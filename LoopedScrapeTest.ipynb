{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source code: https://www.datacamp.com/community/tutorials/web-scraping-using-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not using currently\n",
    "years=['2020','2019','2018','2017','2016','2015','2014','2013','2012','2011','2010','2009',\n",
    "       '2008','2007','2006','2005','2004','2003','2002','2001','2000','1999','1998','1997',\n",
    "       '1996','1995','1994','1993','1992','1991','1990','1989','1988','1987','1986','1985',\n",
    "       '1984','1983','1982','1981','1980','1979','1978','1977','1976','1975','1974','1973',\n",
    "       '1972','1971','1970','1969','1968','1967','1966','1965','1964','1963','1962','1961',\n",
    "       '1960']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n",
      "2019\n",
      "2018\n",
      "2017\n",
      "2016\n",
      "2015\n",
      "2014\n",
      "2013\n",
      "2012\n",
      "2011\n",
      "2010\n",
      "2009\n",
      "2008\n",
      "2007\n",
      "2006\n",
      "2005\n",
      "2004\n",
      "2003\n",
      "2002\n",
      "2001\n",
      "2000\n",
      "1999\n",
      "1998\n",
      "1997\n",
      "1996\n",
      "1995\n",
      "1994\n",
      "1993\n",
      "1992\n",
      "1991\n",
      "1990\n",
      "1989\n",
      "1988\n",
      "1987\n",
      "1986\n",
      "1985\n",
      "1984\n",
      "1983\n",
      "1982\n",
      "1981\n",
      "1980\n",
      "1979\n",
      "1978\n",
      "1977\n",
      "1976\n",
      "1975\n",
      "1974\n",
      "1973\n",
      "1972\n",
      "1971\n",
      "1970\n",
      "1969\n",
      "1968\n",
      "1967\n",
      "1966\n",
      "1965\n",
      "1964\n",
      "1963\n",
      "1962\n",
      "1961\n",
      "1960\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    print(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URLs for for loop\n",
    "urls = [\"https://www.hockey-reference.com/leagues/NHL_2020_skaters.html\",\n",
    "        \"https://www.hockey-reference.com/leagues/NHL_2019_skaters.html\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-20 finished scraping\n",
      "2018-19 finished scraping\n"
     ]
    }
   ],
   "source": [
    "#For loop to create dataframe of season stats\n",
    "#testing it out with only 2 URLs\n",
    "import re\n",
    "list_rows = []\n",
    "season = []\n",
    "for url in urls:\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    rows = soup.find_all('tr')\n",
    "    title = soup.title.get_text()[0:7]\n",
    "    \n",
    "    print(title, \"finished scraping\")\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        str_cells = str(cells)\n",
    "        clean = re.compile('<.*?>')\n",
    "        clean2 = (re.sub(clean, '',str_cells))\n",
    "        list_rows.append(clean2)\n",
    "        title = soup.title.get_text()[0:7]\n",
    "        season.append(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## currently trying to get a column to display the season for each row of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list_rows)\n",
    "df.append(season)\n",
    "df1 = df[0].str.split(',', expand=True)\n",
    "df1[0] = df1[0].str.strip('[')\n",
    "df1[26] = df1[26].str.strip(']')\n",
    "df1 = df1.iloc[2:]\n",
    "df1 = df1.reset_index(drop=True)\n",
    "df2 = df1.set_axis(['Player', 'Age', 'Tm', 'Pos', 'GP', 'G', 'A', 'PTS', 'PlusMinus', 'PIM', 'PS', 'EV', 'PP', 'SH', 'GW', 'EV', 'PP', 'SH', 'S', 'Spct', 'TOI', 'ATOI', 'BLK', 'HIT', 'FOW', 'FOL', 'FOpct'], axis=1, inplace=False)\n",
    "df2.reset_index\n",
    "df2.drop(df2[df2['Player'] == ']'].index, inplace = True)\n",
    "df2.reset_index(drop=True)\n",
    "df2.to_csv('Looped_Skater_Data.csv', index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code below this cell is copied over from 'ScrapeTest.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'lxml')\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = soup.title\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = soup.find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows:\n",
    "    row_td = row.find_all('td')\n",
    "print(row_td)\n",
    "type(row_td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_cells = str(row_td)\n",
    "cleantext = BeautifulSoup(str_cells, \"lxml\").get_text()\n",
    "print(cleantext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "list_rows = []\n",
    "for row in rows:\n",
    "    cells = row.find_all('td')\n",
    "    str_cells = str(cells)\n",
    "    clean = re.compile('<.*?>')\n",
    "    clean2 = (re.sub(clean, '',str_cells))\n",
    "    list_rows.append(clean2)\n",
    "print(clean2)\n",
    "type(clean2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list_rows)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[0].str.split(',', expand=True)\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[0] = df1[0].str.strip('[')\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[26] = df1[26].str.strip(']')\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.iloc[2:]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.reset_index(drop=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.set_axis(['Player', 'Age', 'Tm', 'Pos', 'GP', 'G', 'A', 'PTS', 'PlusMinus', 'PIM', 'PS', 'EV', 'PP', 'SH', 'GW', 'EV', 'PP', 'SH', 'S', 'Spct', 'TOI', 'ATOI', 'BLK', 'HIT', 'FOW', 'FOL', 'FOpct'], axis=1, inplace=False)\n",
    "df2.reset_index\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(df2[df2['Player'] == ']'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Season']='2019-2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('2019_2020.csv', index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
